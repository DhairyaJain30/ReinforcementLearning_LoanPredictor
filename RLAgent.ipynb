{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dWboNsN3Mmk-",
        "outputId": "455e4f4b-a940-481d-cec1-48002df9b992"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting d3rlpy\n",
            "  Downloading d3rlpy-2.8.1-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: pyarrow in /usr/local/lib/python3.12/dist-packages (18.1.0)\n",
            "Requirement already satisfied: torch>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from d3rlpy) (2.8.0+cu126)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.12/dist-packages (from d3rlpy) (4.67.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.12/dist-packages (from d3rlpy) (3.15.1)\n",
            "Collecting gym>=0.26.0 (from d3rlpy)\n",
            "  Downloading gym-0.26.2.tar.gz (721 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m721.7/721.7 kB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from d3rlpy) (8.3.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.12/dist-packages (from d3rlpy) (4.15.0)\n",
            "Collecting structlog (from d3rlpy)\n",
            "  Downloading structlog-25.4.0-py3-none-any.whl.metadata (7.6 kB)\n",
            "Collecting colorama (from d3rlpy)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Collecting dataclasses-json (from d3rlpy)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting gymnasium==1.0.0 (from d3rlpy)\n",
            "  Downloading gymnasium-1.0.0-py3-none-any.whl.metadata (9.5 kB)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from d3rlpy) (1.6.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.12/dist-packages (from gymnasium==1.0.0->d3rlpy) (2.0.2)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from gymnasium==1.0.0->d3rlpy) (3.1.1)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.12/dist-packages (from gymnasium==1.0.0->d3rlpy) (0.0.4)\n",
            "Requirement already satisfied: gym_notices>=0.0.4 in /usr/local/lib/python3.12/dist-packages (from gym>=0.26.0->d3rlpy) (0.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=2.5.0->d3rlpy) (3.20.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.5.0->d3rlpy) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.5.0->d3rlpy) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=2.5.0->d3rlpy) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.5.0->d3rlpy) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=2.5.0->d3rlpy) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.5.0->d3rlpy) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.5.0->d3rlpy) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.5.0->d3rlpy) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.5.0->d3rlpy) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.5.0->d3rlpy) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.5.0->d3rlpy) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.5.0->d3rlpy) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.5.0->d3rlpy) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.5.0->d3rlpy) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.5.0->d3rlpy) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.5.0->d3rlpy) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.5.0->d3rlpy) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.5.0->d3rlpy) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.5.0->d3rlpy) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.5.0->d3rlpy) (3.4.0)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json->d3rlpy)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json->d3rlpy)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->d3rlpy) (1.16.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->d3rlpy) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->d3rlpy) (3.6.0)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.12/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->d3rlpy) (25.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.5.0->d3rlpy) (1.3.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json->d3rlpy)\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.5.0->d3rlpy) (3.0.3)\n",
            "Downloading d3rlpy-2.8.1-py3-none-any.whl (201 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.1/201.1 kB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gymnasium-1.0.0-py3-none-any.whl (958 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m958.1/958.1 kB\u001b[0m \u001b[31m53.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading structlog-25.4.0-py3-none-any.whl (68 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.7/68.7 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Building wheels for collected packages: gym\n",
            "  Building wheel for gym (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gym: filename=gym-0.26.2-py3-none-any.whl size=827727 sha256=9ce81b3e3674637f64099dfa5bcdc7c59234b4a08379eb44d4360774b6a7a8c7\n",
            "  Stored in directory: /root/.cache/pip/wheels/95/51/6c/9bb05ebbe7c5cb8171dfaa3611f32622ca4658d53f31c79077\n",
            "Successfully built gym\n",
            "Installing collected packages: structlog, mypy-extensions, marshmallow, gymnasium, gym, colorama, typing-inspect, dataclasses-json, d3rlpy\n",
            "  Attempting uninstall: gymnasium\n",
            "    Found existing installation: gymnasium 1.2.1\n",
            "    Uninstalling gymnasium-1.2.1:\n",
            "      Successfully uninstalled gymnasium-1.2.1\n",
            "  Attempting uninstall: gym\n",
            "    Found existing installation: gym 0.25.2\n",
            "    Uninstalling gym-0.25.2:\n",
            "      Successfully uninstalled gym-0.25.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "dopamine-rl 4.1.2 requires gym<=0.25.2, but you have gym 0.26.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed colorama-0.4.6 d3rlpy-2.8.1 dataclasses-json-0.6.7 gym-0.26.2 gymnasium-1.0.0 marshmallow-3.26.1 mypy-extensions-1.1.0 structlog-25.4.0 typing-inspect-0.9.0\n"
          ]
        }
      ],
      "source": [
        "!pip install d3rlpy pyarrow"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import d3rlpy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TEI85STA891e",
        "outputId": "956f2088-d169-47ca-9e46-e84716df9bd5"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Gym has been unmaintained since 2022 and does not support NumPy 2.0 amongst other critical functionality.\n",
            "Please upgrade to Gymnasium, the maintained drop-in replacement of Gym, or contact the authors of your software and request that they upgrade.\n",
            "Users of this version of Gym should be able to simply replace 'import gym' with 'import gymnasium as gym' in the vast majority of cases.\n",
            "See the migration guide at https://gymnasium.farama.org/introduction/migration_guide/ for additional information.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "d3rlpy.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "3cuoFxQP8cIx",
        "outputId": "4067b103-d3f0-4627-cd21-22338e598c19"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.8.1'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from d3rlpy.metrics import EnvironmentEvaluator"
      ],
      "metadata": {
        "id": "zzZlTt_TFTcL"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import warnings\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import (\n",
        "    StandardScaler, OneHotEncoder, OrdinalEncoder, FunctionTransformer\n",
        ")\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.compose import ColumnTransformer\n",
        "\n",
        "import d3rlpy\n",
        "from d3rlpy.dataset import MDPDataset\n",
        "from d3rlpy.algos import DiscreteCQLConfig\n",
        "from d3rlpy.ope import FQEConfig, DiscreteFQE\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "print(f\"Using d3rlpy version: {d3rlpy.__version__}\")\n",
        "\n",
        "# =============================\n",
        "# STEP 1 — Preprocessing\n",
        "# =============================\n",
        "def build_preprocessor(X_data):\n",
        "    log_transform_features = [\n",
        "        'annual_inc', 'tot_coll_amt', 'delinq_amnt', 'tax_liens',\n",
        "        'pub_rec', 'revol_bal', 'tot_cur_bal'\n",
        "    ]\n",
        "    numeric_features = [\n",
        "        'loan_amnt', 'funded_amnt', 'installment', 'fico_range_low',\n",
        "        'num_tl_op_past_12m', 'acc_open_past_24mths', 'inq_last_6mths', 'dti',\n",
        "        'revol_util', 'open_acc', 'mort_acc', 'bc_util', 'emp_length_int',\n",
        "        'credit_history_length_mths', 'avg_cur_bal', 'bc_open_to_buy',\n",
        "        'chargeoff_within_12_mths', 'delinq_2yrs', 'mo_sin_old_il_acct',\n",
        "        'mo_sin_old_rev_tl_op', 'mo_sin_rcnt_rev_tl_op', 'mo_sin_rcnt_tl',\n",
        "        'mths_since_recent_bc', 'num_accts_ever_120_pd', 'num_actv_bc_tl',\n",
        "        'num_actv_rev_tl', 'num_bc_sats', 'num_bc_tl', 'num_il_tl',\n",
        "        'num_op_rev_tl', 'num_rev_accts', 'num_rev_tl_bal_gt_0', 'num_sats',\n",
        "        'num_tl_120dpd_2m', 'num_tl_30dpd', 'num_tl_90g_dpd_24m',\n",
        "        'pct_tl_nvr_dlq', 'percent_bc_gt_75', 'pub_rec_bankruptcies',\n",
        "        'tot_hi_cred_lim', 'total_bal_ex_mort', 'total_bc_limit',\n",
        "        'total_il_high_credit_limit', 'total_acc', 'total_rev_hi_lim'\n",
        "    ]\n",
        "    categorical_features = [\n",
        "        'verification_status', 'home_ownership', 'purpose',\n",
        "        'initial_list_status', 'application_type'\n",
        "    ]\n",
        "    ordinal_features = ['grade', 'sub_grade', 'term']\n",
        "\n",
        "    existing_cols = X_data.columns\n",
        "    log_transform_features = [c for c in log_transform_features if c in existing_cols]\n",
        "    numeric_features = [c for c in numeric_features if c in existing_cols]\n",
        "    categorical_features = [c for c in categorical_features if c in existing_cols]\n",
        "    ordinal_features = [c for c in ordinal_features if c in existing_cols]\n",
        "\n",
        "    grade_cats = sorted(X_data['grade'].dropna().unique()) if 'grade' in X_data else []\n",
        "    sub_grade_cats = sorted(X_data['sub_grade'].dropna().unique()) if 'sub_grade' in X_data else []\n",
        "    term_cats = sorted(X_data['term'].dropna().unique()) if 'term' in X_data else []\n",
        "    ordinal_categories = [grade_cats, sub_grade_cats, term_cats]\n",
        "\n",
        "    log_pipeline = Pipeline([\n",
        "        ('imputer', SimpleImputer(strategy='median')),\n",
        "        ('log', FunctionTransformer(np.log1p, validate=False)),\n",
        "        ('scale', StandardScaler())\n",
        "    ])\n",
        "    numeric_pipeline = Pipeline([\n",
        "        ('imputer', SimpleImputer(strategy='median')),\n",
        "        ('scale', StandardScaler())\n",
        "    ])\n",
        "    categorical_pipeline = Pipeline([\n",
        "        ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "        ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
        "    ])\n",
        "    ordinal_pipeline = Pipeline([\n",
        "        ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "        ('encode', OrdinalEncoder(categories=ordinal_categories, handle_unknown='use_encoded_value', unknown_value=-1))\n",
        "    ])\n",
        "\n",
        "    preprocessor = ColumnTransformer([\n",
        "        ('log', log_pipeline, log_transform_features),\n",
        "        ('num', numeric_pipeline, numeric_features),\n",
        "        ('cat', categorical_pipeline, categorical_features),\n",
        "        ('ord', ordinal_pipeline, ordinal_features)\n",
        "    ], remainder='drop')\n",
        "\n",
        "    all_features = log_transform_features + numeric_features + categorical_features + ordinal_features\n",
        "    return preprocessor, all_features\n",
        "\n",
        "\n",
        "# =============================\n",
        "# STEP 2 — Load Data\n",
        "# =============================\n",
        "print(\"Loading data...\")\n",
        "df_rl = pd.read_parquet('processed_loan_data.parquet')\n",
        "\n",
        "df_rl['reward'] = np.where(df_rl['is_default'] == 1, -df_rl['loan_amnt'],\n",
        "                           df_rl['loan_amnt'] * (df_rl['int_rate'] / 100.0))\n",
        "df_rl['terminal'] = 1\n",
        "\n",
        "# two possible actions: 0 = deny, 1 = approve\n",
        "df_rl['action'] = np.random.choice([0, 1], size=len(df_rl))\n",
        "\n",
        "# =============================\n",
        "# STEP 3 — Transform Data\n",
        "# =============================\n",
        "preprocessor, used_features = build_preprocessor(df_rl)\n",
        "X = preprocessor.fit_transform(df_rl[used_features]).astype(np.float32)\n",
        "X = np.nan_to_num(X, nan=0.0)\n",
        "\n",
        "actions = df_rl['action'].values.astype(np.int32)\n",
        "rewards = df_rl['reward'].values.astype(np.float32)\n",
        "terminals = df_rl['terminal'].values.astype(np.float32)\n",
        "\n",
        "# =============================\n",
        "# STEP 4 — Split into train/test\n",
        "# =============================\n",
        "train_idx, test_idx = train_test_split(np.arange(len(X)), test_size=0.2, random_state=42)\n",
        "train_data = MDPDataset(X[train_idx], actions[train_idx], rewards[train_idx], terminals[train_idx])\n",
        "test_data = MDPDataset(X[test_idx], actions[test_idx], rewards[test_idx], terminals[test_idx])\n",
        "\n",
        "print(f\"Train: {len(train_idx)}, Test: {len(test_idx)}\")\n",
        "\n",
        "# =============================\n",
        "# STEP 5 — Offline RL: Discrete CQL\n",
        "# =============================\n",
        "use_gpu = torch.cuda.is_available()\n",
        "device = \"cuda:0\" if use_gpu else \"cpu\"\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "cql = DiscreteCQLConfig().create(device=device)\n",
        "print(\"Training Discrete CQL (offline)...\")\n",
        "\n",
        "cql.fit(train_data, n_steps=50_000)\n",
        "cql.save_model(\"discrete_cql_model.pt\")\n",
        "\n",
        "# =============================\n",
        "# STEP 6 — Offline Evaluation: FQE\n",
        "# =============================\n",
        "print(\"\\nRunning Fitted Q Evaluation (FQE)...\")\n",
        "\n",
        "fqe_config = FQEConfig()\n",
        "fqe = DiscreteFQE(algo=cql, config=fqe_config, device=device)\n",
        "\n",
        "fqe.fit(dataset=train_data, n_steps=25_000)\n",
        "estimated_value = fqe.evaluate(dataset=test_data)\n",
        "\n",
        "print(\"\\n===================================\")\n",
        "print(\"  Offline Policy Evaluation Result  \")\n",
        "print(\"===================================\")\n",
        "print(f\"Estimated Policy Value (FQE): {estimated_value:.2f}\")\n",
        "print(\"===================================\")\n"
      ],
      "metadata": {
        "id": "oj0tYiBRFcA-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}